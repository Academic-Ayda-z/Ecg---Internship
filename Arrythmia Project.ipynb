{"cells":[{"cell_type":"markdown","metadata":{"id":"j5aGTXyuMu_k"},"source":["# Introduction"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"7rtu_KNjAuX3","executionInfo":{"status":"error","timestamp":1683545067338,"user_tz":-210,"elapsed":10787,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}},"outputId":"3a99ef23-8c12-487c-beaa-e9a2cb154411"},"execution_count":3,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"markdown","metadata":{"id":"ozfmdbdZMu_q"},"source":["Recently, I was reviewing Andrew Ng's team's work(https://stanfordmlgroup.github.io/projects/ecg/) on heart arrhythmia detector with convolutional neural networks (CNN). I found this quite fascinating especially with emergence of wearable products (e.g. Apple Watch and portable EKG machines) that are capable of monitoring your heart while at home. As such, I was curious how to build a machine learning algorithm that could detect abnormal heart beats. Here we will use an ECG signal (continuous electrical measurement of the heart) and train 3 neural networks to predict heart arrythmias: dense neural network, CNN, and LSTM.  "]},{"cell_type":"markdown","metadata":{"id":"8nIXlnZ5Mu_r"},"source":["# Dataset"]},{"cell_type":"markdown","metadata":{"id":"oxLCIVawMu_s"},"source":["We will use the MIH-BIH Arrythmia dataset from https://physionet.org/content/mitdb/1.0.0/. This is a dataset with 48 half-hour two-channel ECG recordings measured at 360 Hz. The recordings have annotations from cardiologists for each heart beat. The symbols for the annotations can be found at https://archive.physionet.org/physiobank/annotations.shtml"]},{"cell_type":"markdown","metadata":{"id":"mVPwv3AqMu_s"},"source":["# Project Definition"]},{"cell_type":"markdown","metadata":{"id":"aBOp9VqsMu_t"},"source":["Predict if a heart beat from the first ECG signal has an arrhythmia for each 6 second window centered on the peak of the heart beat. "]},{"cell_type":"markdown","metadata":{"id":"zbegIoVEMu_t"},"source":["To simplify the problem, we will assume that a QRS detector is capable of automatically identifying the peak of each heart beat. We will ignore any non-beat annotations and any heart beats in the first or last 3 seconds of the recording due to reduced data. We will use a window of 6 seconds so we can compare the current beat to beats just before and after. This decision was based after talking to a physician who said it is easier to identify if you have something to compare it to. "]},{"cell_type":"markdown","metadata":{"id":"F76M0-UNMu_u"},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lx6np1cTMu_v","executionInfo":{"status":"ok","timestamp":1683545073162,"user_tz":-210,"elapsed":721,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from os import listdir\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SPSXqMckMu_x","executionInfo":{"status":"ok","timestamp":1683545075504,"user_tz":-210,"elapsed":7,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["# data must be downloaded and path provided\n","data_path = '/content/'\n","#'mit-bih-arrhythmia-database-1.0.0/'\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-K6eIYp-Mu_z","executionInfo":{"status":"ok","timestamp":1683545078182,"user_tz":-210,"elapsed":8,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["# list of patients\n","pts = ['100','101','102','103','104','105','106','107',\n","       '108','109','111','112','113','114','115','116',\n","       '117','118','119','121','122','123','124','200',\n","       '201','202','203','205','207','208','209','210',\n","       '212','213','214','215','217','219','220','221',\n","       '222','223','228','230','231','232','233','234']"]},{"cell_type":"markdown","metadata":{"id":"xbVEmNXjMu_0"},"source":["Here we will use a pypi package wfdb for loading the ecg and annotations.  "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"DGLm7JB_Mu_0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683545086588,"user_tz":-210,"elapsed":6060,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}},"outputId":"1b6896b6-05cc-483b-fae8-f31e7e6207a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wfdb\n","  Downloading wfdb-4.1.1-py3-none-any.whl (159 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (0.12.1)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.5.3)\n","Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (2.27.1)\n","Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.22.4)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.10.1)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb) (3.7.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (23.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (8.4.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (4.39.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->wfdb) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2022.12.7)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.21)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n","Installing collected packages: wfdb\n","Successfully installed wfdb-4.1.1\n"]}],"source":["!pip install wfdb\n","import wfdb"]},{"cell_type":"markdown","metadata":{"id":"T6tllEpvMu_0"},"source":["Let's load all the annotations and see the distribution of heart beat types across all files. "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"f2_C3a_jMu_1","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"error","timestamp":1683545094743,"user_tz":-210,"elapsed":13,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}},"outputId":"bea3495c-b49a-4067-9bad-37f62393224b"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-2583a940f346>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'atr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wfdb/io/annotation.py\u001b[0m in \u001b[0;36mrdann\u001b[0;34m(record_name, extension, sampfrom, sampto, shift_samps, pn_dir, return_label_elements, summarize_labels)\u001b[0m\n\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;31m# Read the file in byte pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1950\u001b[0;31m     \u001b[0mfilebytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_byte_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpn_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m     \u001b[0;31m# Get WFDB annotation fields from the file bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wfdb/io/annotation.py\u001b[0m in \u001b[0;36mload_byte_pairs\u001b[0;34m(record_name, extension, pn_dir)\u001b[0m\n\u001b[1;32m   2089\u001b[0m     \u001b[0;31m# local file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpn_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m             \u001b[0mfilebytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<u1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m     \u001b[0;31m# PhysioNet file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/100.atr'"]}],"source":["df = pd.DataFrame()\n","\n","for pt in pts:\n","    file = data_path + pt\n","    annotation = wfdb.rdann(file, 'atr')\n","    sym = annotation.symbol\n","    \n","    values, counts = np.unique(sym, return_counts=True)\n","    df_sub = pd.DataFrame({'sym':values, 'val':counts, 'pt':[pt]*len(counts)})\n","    df = pd.concat([df, df_sub],axis = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thOAfmuHMu_1","executionInfo":{"status":"aborted","timestamp":1683545067353,"user_tz":-210,"elapsed":114,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["df.groupby('sym').val.sum().sort_values(ascending = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7xg63x9TMu_4","executionInfo":{"status":"aborted","timestamp":1683545067354,"user_tz":-210,"elapsed":115,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["# list of nonbeat and abnormal\n","nonbeat = ['[','!',']','x','(',')','p','t','u','`',\n","           '\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n","abnormal = ['L','R','V','/','A','f','F','j','a','E','J','e','S']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MpVWQBMGMu_5","executionInfo":{"status":"aborted","timestamp":1683545067355,"user_tz":-210,"elapsed":115,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["# break into normal, abnormal or nonbeat\n","df['cat'] = -1\n","df.loc[df.sym == 'N','cat'] = 0\n","df.loc[df.sym.isin(abnormal), 'cat'] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjr8SE_3Mu_5","executionInfo":{"status":"aborted","timestamp":1683545067355,"user_tz":-210,"elapsed":115,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["df.groupby('cat').val.sum()"]},{"cell_type":"markdown","metadata":{"id":"0C9gGYB_Mu_7"},"source":["Let's write a function for loading a single patient's signals and annotations. Note the annotation values are the indices of the signal array. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsYWKQpFMu_7","executionInfo":{"status":"aborted","timestamp":1683545067356,"user_tz":-210,"elapsed":115,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["def load_ecg(file):\n","    # load the ecg\n","    # example file: 'mit-bih-arrhythmia-database-1.0.0/101'\n","    \n","    # load the ecg\n","    record = wfdb.rdrecord(file)\n","    # load the annotation\n","    annotation = wfdb.rdann(file, 'atr')\n","    \n","    # extract the signal\n","    p_signal = record.p_signal\n","    \n","    # verify frequency is 360\n","    assert record.fs == 360, 'sample freq is not 360'\n","    \n","    # extract symbols and annotation index\n","    atr_sym = annotation.symbol\n","    atr_sample = annotation.sample\n","    \n","    return p_signal, atr_sym, atr_sample "]},{"cell_type":"markdown","metadata":{"id":"-i8Ix4mKMu_8"},"source":["Let's check out what abnormal beats are in a patient's ecg:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_oOM8nTkMu_8","executionInfo":{"status":"aborted","timestamp":1683545067357,"user_tz":-210,"elapsed":116,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["file = data_path + pts[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAl4SA9jMu_9","executionInfo":{"status":"aborted","timestamp":1683545067357,"user_tz":-210,"elapsed":116,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["p_signal, atr_sym, atr_sample = load_ecg(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCra3F3ZMu_-","executionInfo":{"status":"aborted","timestamp":1683545067358,"user_tz":-210,"elapsed":114,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["values, counts = np.unique(sym, return_counts=True)\n","for v,c in zip(values, counts):\n","    print(v,c)"]},{"cell_type":"markdown","metadata":{"id":"IDKbDOYIMu__"},"source":["Let's make a plot of these, zooming in on one of the abnormal beats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEhLXpc8Mu__","executionInfo":{"status":"aborted","timestamp":1683545067358,"user_tz":-210,"elapsed":113,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["# get abnormal beat index\n","ab_index = [b for a,b in zip(atr_sym,atr_sample) if a in abnormal][:10]\n","ab_index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kIQOFwruMvAA","executionInfo":{"status":"aborted","timestamp":1683545067359,"user_tz":-210,"elapsed":112,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["x = np.arange(len(p_signal))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9Hr26IRMvAA","executionInfo":{"status":"aborted","timestamp":1683545067359,"user_tz":-210,"elapsed":111,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["left = ab_index[1]-1080\n","right = ab_index[1]+1080\n","\n","plt.plot(x[left:right],p_signal[left:right,0],'-',label='ecg',)\n","plt.plot(x[atr_sample],p_signal[atr_sample,0],'go',label ='normal')\n","plt.plot(x[ab_index],p_signal[ab_index,0],'ro',label='abnormal')\n","\n","plt.xlim(left,right)\n","plt.ylim(p_signal[left:right].min()-0.05,p_signal[left:right,0].max()+0.05)\n","plt.xlabel('time index')\n","plt.ylabel('ECG signal')\n","plt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"MAhcB7t6MvAB"},"source":["# Make a dataset"]},{"cell_type":"markdown","metadata":{"id":"SGoAzUp4MvAC"},"source":["Let's make a dataset that is centered on beats with +- 3 seconds before and after. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CX-dks5KMvAC","executionInfo":{"status":"aborted","timestamp":1683545067360,"user_tz":-210,"elapsed":111,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["def make_dataset(pts, num_sec, fs, abnormal):\n","    # function for making dataset ignoring non-beats\n","    # input:\n","    # pts - list of patients\n","    # num_sec = number of seconds to include before and after the beat\n","    # fs = frequency\n","    # output: \n","    #   X_all = signal (nbeats , num_sec * fs columns)\n","    #   Y_all = binary is abnormal (nbeats, 1)\n","    #   sym_all = beat annotation symbol (nbeats,1)\n","    \n","    # initialize numpy arrays\n","    num_cols = 2*num_sec * fs\n","    X_all = np.zeros((1,num_cols))\n","    Y_all = np.zeros((1,1))\n","    sym_all = []\n","    \n","    # list to keep track of number of beats across patients\n","    max_rows = []\n","    \n","    for pt in pts:\n","        file = data_path + pt\n","        \n","        p_signal, atr_sym, atr_sample = load_ecg(file)\n","        \n","        # grab the first signal\n","        p_signal = p_signal[:,0]\n","        \n","        # make df to exclude the nonbeats\n","        df_ann = pd.DataFrame({'atr_sym':atr_sym,\n","                              'atr_sample':atr_sample})\n","        df_ann = df_ann.loc[df_ann.atr_sym.isin(abnormal + ['N'])]\n","        \n","        X,Y,sym = build_XY(p_signal,df_ann, num_cols, abnormal)\n","        sym_all = sym_all+sym\n","        max_rows.append(X.shape[0])\n","        X_all = np.append(X_all,X,axis = 0)\n","        Y_all = np.append(Y_all,Y,axis = 0)\n","    # drop the first zero row\n","    X_all = X_all[1:,:]\n","    Y_all = Y_all[1:,:]\n","    \n","    # check sizes make sense\n","    assert np.sum(max_rows) == X_all.shape[0], 'number of X, max_rows rows messed up'\n","    assert Y_all.shape[0] == X_all.shape[0], 'number of X, Y rows messed up'\n","    assert Y_all.shape[0] == len(sym_all), 'number of Y, sym rows messed up'\n","\n","    return X_all, Y_all, sym_all\n","\n","\n","\n","def build_XY(p_signal, df_ann, num_cols, abnormal):\n","    # this function builds the X,Y matrices for each beat\n","    # it also returns the original symbols for Y\n","    \n","    num_rows = len(df_ann)\n","\n","    X = np.zeros((num_rows, num_cols))\n","    Y = np.zeros((num_rows,1))\n","    sym = []\n","    \n","    # keep track of rows\n","    max_row = 0\n","\n","    for atr_sample, atr_sym in zip(df_ann.atr_sample.values,df_ann.atr_sym.values):\n","\n","        left = max([0,(atr_sample - num_sec*fs) ])\n","        right = min([len(p_signal),(atr_sample + num_sec*fs) ])\n","        x = p_signal[left: right]\n","        if len(x) == num_cols:\n","            X[max_row,:] = x\n","            Y[max_row,:] = int(atr_sym in abnormal)\n","            sym.append(atr_sym)\n","            max_row += 1\n","    X = X[:max_row,:]\n","    Y = Y[:max_row,:]\n","    return X,Y,sym\n","    "]},{"cell_type":"markdown","metadata":{"id":"CVVDIWNaMvAE"},"source":["# Lesson 1: split on patients not on samples"]},{"cell_type":"markdown","metadata":{"id":"yRGJrXD8MvAF"},"source":["Let's start by processing all of our patients."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDrnfWlzMvAF","executionInfo":{"status":"aborted","timestamp":1683545067361,"user_tz":-210,"elapsed":110,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["num_sec = 3\n","fs = 360"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_-uFb89MvAG","executionInfo":{"status":"aborted","timestamp":1683545067361,"user_tz":-210,"elapsed":109,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["X_all, Y_all, sym_all = make_dataset(pts, num_sec, fs, abnormal)"]},{"cell_type":"markdown","metadata":{"id":"FhqEw2UHMvAG"},"source":["Imagine we naively just decided to randomly split our data by samples into a train and validation set. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pu19vWz4MvAH","executionInfo":{"status":"aborted","timestamp":1683545067362,"user_tz":-210,"elapsed":109,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X_all, Y_all, test_size=0.33, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"vJ1abdf0MvAI"},"source":["Now we are ready to build our first dense NN. We will do this in Keras for simplicity. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zc-HsHDAMvAJ","executionInfo":{"status":"aborted","timestamp":1683545067362,"user_tz":-210,"elapsed":107,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Dropout\n","from keras.utils import to_categorical"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGIoWi_kMvAK","executionInfo":{"status":"aborted","timestamp":1683545067363,"user_tz":-210,"elapsed":106,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["# build the same model\n","# lets test out relu (a different activation function) and add drop out (for regularization)\n","model = Sequential()\n","model.add(Dense(32, activation = 'relu', input_dim = X_train.shape[1]))\n","model.add(Dropout(rate = 0.25))\n","model.add(Dense(1, activation = 'sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJeq_YzHMvAL","executionInfo":{"status":"aborted","timestamp":1683545067363,"user_tz":-210,"elapsed":105,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["# compile the model - use categorical crossentropy, and the adam optimizer\n","model.compile(\n","                loss = 'binary_crossentropy',\n","                optimizer = 'adam',\n","                metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-mj4FfE7MvAM","executionInfo":{"status":"aborted","timestamp":1683545067364,"user_tz":-210,"elapsed":105,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["model.fit(X_train, y_train, batch_size = 32, epochs= 5, verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_E9LnYyWMvAN","executionInfo":{"status":"aborted","timestamp":1683545067364,"user_tz":-210,"elapsed":104,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n","def calc_prevalence(y_actual):\n","    return (sum(y_actual)/len(y_actual))\n","def calc_specificity(y_actual, y_pred, thresh):\n","    # calculates specificity\n","    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n","def print_report(y_actual, y_pred, thresh):\n","    \n","    auc = roc_auc_score(y_actual, y_pred)\n","    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n","    recall = recall_score(y_actual, (y_pred > thresh))\n","    precision = precision_score(y_actual, (y_pred > thresh))\n","    specificity = calc_specificity(y_actual, y_pred, thresh)\n","    print('AUC:%.3f'%auc)\n","    print('accuracy:%.3f'%accuracy)\n","    print('recall:%.3f'%recall)\n","    print('precision:%.3f'%precision)\n","    print('specificity:%.3f'%specificity)\n","    print('prevalence:%.3f'%calc_prevalence(y_actual))\n","    print(' ')\n","    return auc, accuracy, recall, precision, specificity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yb7vYHRiMvAO","executionInfo":{"status":"aborted","timestamp":1683545067364,"user_tz":-210,"elapsed":103,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["#y_train_preds_dense = model.predict_proba(X_train,verbose = 1)\n","\n","#y_valid_preds_dense = model.predict_proba(X_valid,verbose = 1)\n","y_train_preds_dense = model.predict(X_train,verbose = 1)\n","\n","y_valid_preds_dense = model.predict(X_valid,verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ws7iv4TuMvAP","executionInfo":{"status":"aborted","timestamp":1683545067365,"user_tz":-210,"elapsed":103,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["thresh = (sum(y_train)/len(y_train))[0]\n","thresh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DP6HY9QGMvAY","executionInfo":{"status":"aborted","timestamp":1683545067365,"user_tz":-210,"elapsed":103,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["print('Train');\n","print_report(y_train, y_train_preds_dense, thresh)\n","print('Valid');\n","print_report(y_valid, y_valid_preds_dense, thresh);"]},{"cell_type":"markdown","metadata":{"id":"ujvZozIDMvAY"},"source":["Amazing! Not that hard! But wait, will this work on new patients? Perhaps not if each patient has a unique heart signature. Technically the same patient can show up in both the training and validation sets. This means that we may have accidentally leaked information across the datasets. "]},{"cell_type":"markdown","metadata":{"id":"GRs7QFSdMvAa"},"source":["We can try this again by splitting on patients instead of samples. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcWaGiJKMvAa","executionInfo":{"status":"aborted","timestamp":1683545067366,"user_tz":-210,"elapsed":103,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["import random\n","random.seed( 42 )\n","pts_train = random.sample(pts, 36)\n","pts_valid = [pt for pt in pts if pt not in pts_train]\n","print(len(pts_train), len(pts_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6QCqNabzMvAb","executionInfo":{"status":"aborted","timestamp":1683545067366,"user_tz":-210,"elapsed":103,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["X_train, y_train, sym_train = make_dataset(pts_train, num_sec, fs, abnormal)\n","X_valid, y_valid, sym_valid = make_dataset(pts_valid, num_sec, fs, abnormal)\n","print(X_train.shape, y_train.shape, len(sym_train))\n","print(X_valid.shape, y_valid.shape, len(sym_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVdpdWdTMvAc","executionInfo":{"status":"aborted","timestamp":1683545067367,"user_tz":-210,"elapsed":104,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["# build the same model\n","# lets test out relu (a different activation function) and add drop out (for regularization)\n","model = Sequential()\n","model.add(Dense(32, activation = 'relu', input_dim = X_train.shape[1]))\n","model.add(Dropout(rate = 0.25))\n","model.add(Dense(1, activation = 'sigmoid'))\n","\n","# compile the model - use categorical crossentropy, and the adam optimizer\n","model.compile(\n","                loss = 'binary_crossentropy',\n","                optimizer = 'adam',\n","                metrics = ['accuracy'])\n","\n","model.fit(X_train, y_train, batch_size = 32, epochs= 5, verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZWGj05RMvAc","executionInfo":{"status":"aborted","timestamp":1683545067367,"user_tz":-210,"elapsed":103,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["#y_train_preds_dense = model.predict_proba(X_train,verbose = 1)\n","#y_valid_preds_dense = model.predict_proba(X_valid,verbose = 1)\n","y_train_preds_dense = model.predict(X_train,verbose = 1)\n","y_valid_preds_dense = model.predict(X_valid,verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Q0YJ53eMvAd","executionInfo":{"status":"aborted","timestamp":1683545067368,"user_tz":-210,"elapsed":104,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["thresh = (sum(y_train)/len(y_train))[0]\n","thresh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FMneWyfEMvAe","executionInfo":{"status":"aborted","timestamp":1683545067368,"user_tz":-210,"elapsed":104,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["print('Train');\n","print_report(y_train, y_train_preds_dense, thresh)\n","print('Valid');\n","print_report(y_valid, y_valid_preds_dense, thresh);"]},{"cell_type":"markdown","metadata":{"id":"53DLSvOiMvAe"},"source":["Validation score is much different now! Makes sense since we had data leakage before. "]},{"cell_type":"markdown","metadata":{"id":"9yEYEhrnMvAf"},"source":["# Lesson 2: learning curve can tells us we should get more data! "]},{"cell_type":"markdown","metadata":{"id":"bcpYUqK4MvAf"},"source":["Given the overfitting between training and validation. Let's make a simple learning curve to see if we should go collect more data. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6vhqRsiMvAg","executionInfo":{"status":"aborted","timestamp":1683545067369,"user_tz":-210,"elapsed":104,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["aucs_train = []\n","aucs_valid = []\n","\n","n_pts = [1,18,36]\n","for n_pt in n_pts:\n","    \n","    print(n_pt)\n","    pts_sub = pts_train[:n_pt]\n","    X_sub, y_sub, sym_sub = make_dataset(pts_sub, num_sec, fs,abnormal)\n","\n","    # build the same model\n","    # lets test out relu (a different activation function) and add drop out (for regularization)\n","    model = Sequential()\n","    model.add(Dense(32, activation = 'relu', input_dim = X_train.shape[1]))\n","    model.add(Dropout(rate = 0.25))\n","    model.add(Dense(1, activation = 'sigmoid'))\n","\n","    # compile the model - use categorical crossentropy, and the adam optimizer\n","    model.compile(\n","                    loss = 'binary_crossentropy',\n","                    optimizer = 'adam',\n","                    metrics = ['accuracy'])\n","\n","    model.fit(X_sub, y_sub, batch_size = 32, epochs= 5, verbose = 0)\n","    #    y_sub_preds_dense = model.predict_proba(X_sub,verbose = 0)\n","   # y_valid_preds_dense = model.predict_proba(X_valid,verbose = 0)\n","    y_sub_preds_dense = model.predict(X_sub,verbose = 0)\n","    y_valid_preds_dense = model.predict(X_valid,verbose = 0)\n","    \n","    auc_train = roc_auc_score(y_sub, y_sub_preds_dense)\n","    auc_valid = roc_auc_score(y_valid, y_valid_preds_dense)\n","    print('-',auc_train, auc_valid)\n","    aucs_train.append(auc_train)\n","    aucs_valid.append(auc_valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VbZIo6BMvAh","executionInfo":{"status":"aborted","timestamp":1683545067369,"user_tz":-210,"elapsed":104,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["plt.plot(n_pts, aucs_train, 'o-',label = 'Train')\n","plt.plot(n_pts, aucs_valid, 'o-',label = 'Valid')\n","plt.xlabel('Number Training Pts')\n","plt.ylabel('AUC')\n","plt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"cJwLdjnFMvAh"},"source":["More data appears to add extra value to the model. "]},{"cell_type":"markdown","metadata":{"id":"TTwFQBdKMvAi"},"source":["# Lesson 3: test multiple types of deep learning models"]},{"cell_type":"markdown","metadata":{"id":"GFPrmS4kMvAi"},"source":["## CNN"]},{"cell_type":"markdown","metadata":{"id":"K2jIwjZlMvAj"},"source":["Let's start by making a CNN. Here we will use a 1 dimensional CNN (as opposed to the 2D CNN for images). "]},{"cell_type":"markdown","metadata":{"id":"CpGdqRitMvAj"},"source":["A CNN is a special type of deep learning algorithm which uses a set of filters and the convolution operator to reduce the number of parameters. This algorithm sparked the state-of-the-art techniques for image classification. Essentially, the way this works for 1D CNN is to take a filter (kernel) of size `kernel_size` starting with the first time stamp. The convolution operator takes the filter and multiplies each element against the first `kernel_size` time steps. These products are then summed for the first cell in the next layer of the neural network. The filter then moves over by `stride` time steps and repeats. The default `stride` in Keras is 1, which we will use. In image classification, most people use `padding` which allows you pick up some features on the edges of the image by adding 'extra' cells, we will use the default padding which is 0. The output of the convolution is then multiplied by a set of weights W and added to a bias b and then passed through a non-linear activation function as in dense neural network. You can then repeat this with addition CNN layers if desired. Here we will use Dropout which is a technique for reducing overfitting by randomly removing some nodes. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3XbQALL6MvAj","executionInfo":{"status":"aborted","timestamp":1683545067370,"user_tz":-210,"elapsed":104,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["# reshape input to be [samples, time steps, features = 1]\n","X_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","X_valid_cnn = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n","\n","print(X_train_cnn.shape)\n","print(X_valid_cnn.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"osZpvh61MvAk","executionInfo":{"status":"aborted","timestamp":1683545067371,"user_tz":-210,"elapsed":105,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["from keras.layers import Conv1D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sr26hxeaMvAl","executionInfo":{"status":"aborted","timestamp":1683545067371,"user_tz":-210,"elapsed":104,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["model = Sequential()\n","model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu', input_shape = (2160,1)))\n","model.add(Dropout(rate = 0.25))\n","model.add(Flatten())\n","model.add(Dense(1, activation = 'sigmoid'))\n","\n","# compile the model - use categorical crossentropy, and the adam optimizer\n","model.compile(\n","                loss = 'binary_crossentropy',\n","                optimizer = 'adam',\n","                metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"69PS8UDTMvAl","executionInfo":{"status":"aborted","timestamp":1683545067373,"user_tz":-210,"elapsed":106,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["model.fit(X_train_cnn, y_train, batch_size = 32, epochs= 2, verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fp02wSoFMvAl","executionInfo":{"status":"aborted","timestamp":1683545067375,"user_tz":-210,"elapsed":108,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["#deleted proba again\n","y_train_preds_cnn = model.predict(X_train_cnn,verbose = 1)\n","y_valid_preds_cnn = model.predict(X_valid_cnn,verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BVLwLkGyMvAm","executionInfo":{"status":"aborted","timestamp":1683545067376,"user_tz":-210,"elapsed":108,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["print('Train');\n","print_report(y_train, y_train_preds_cnn, thresh)\n","print('Valid');\n","print_report(y_valid, y_valid_preds_cnn, thresh);"]},{"cell_type":"markdown","metadata":{"id":"zGTDKm7uMvAn"},"source":["## LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RcuGJlC8MvAn","executionInfo":{"status":"aborted","timestamp":1683545067377,"user_tz":-210,"elapsed":109,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPaZ9_SJMvAn","executionInfo":{"status":"aborted","timestamp":1683545067377,"user_tz":-210,"elapsed":109,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["from keras.layers import Bidirectional, LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivIi_iRKMvAr","executionInfo":{"status":"aborted","timestamp":1683545067378,"user_tz":-210,"elapsed":109,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["model = Sequential()\n","model.add(Bidirectional(LSTM(64, input_shape=(X_train_cnn.shape[1], X_train_cnn.shape[2]))))\n","model.add(Dropout(rate = 0.25))\n","model.add(Dense(1, activation = 'sigmoid'))\n","model.compile(\n","                loss = 'binary_crossentropy',\n","                optimizer = 'adam',\n","                metrics = ['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"0Qq3BvaCMvAs"},"source":["Reduce dataset to make this feasible for weekend project"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfvZMsydMvAs","executionInfo":{"status":"aborted","timestamp":1683545067378,"user_tz":-210,"elapsed":109,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["model.fit(X_train_cnn[:10000], y_train[:10000], batch_size = 32, epochs= 1, verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XaV4ygNlMvAt","executionInfo":{"status":"aborted","timestamp":1683545067378,"user_tz":-210,"elapsed":108,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["#deleted _proba\n","y_train_preds_lstm = model.predict(X_train_cnn[:10000],verbose = 1)\n","y_valid_preds_lstm = model.predict(X_valid_cnn,verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APpHIwrgMvAy","executionInfo":{"status":"aborted","timestamp":1683545067379,"user_tz":-210,"elapsed":108,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["print('Train');\n","print_report(y_train[:10000], y_train_preds_lstm, thresh)\n","print('Valid');\n","print_report(y_valid, y_valid_preds_lstm, thresh);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WbFlx6z7MvAy","executionInfo":{"status":"aborted","timestamp":1683545067379,"user_tz":-210,"elapsed":108,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":["from sklearn.metrics import roc_curve, roc_auc_score\n","\n","\n","fpr_valid_cnn, tpr_valid_cnn, t_valid_cnn = roc_curve(y_valid, y_valid_preds_cnn)\n","auc_valid_cnn = roc_auc_score(y_valid, y_valid_preds_cnn)\n","\n","fpr_valid_dense, tpr_valid_dense, t_valid_dense = roc_curve(y_valid, y_valid_preds_dense)\n","auc_valid_dense = roc_auc_score(y_valid, y_valid_preds_dense)\n","\n","fpr_valid_lstm, tpr_valid_lstm, t_valid_lstm = roc_curve(y_valid, y_valid_preds_lstm)\n","auc_valid_lstm = roc_auc_score(y_valid, y_valid_preds_lstm)\n","\n","plt.plot(fpr_valid_cnn, tpr_valid_cnn, 'g-', label = 'CNN AUC:%.3f'%auc_valid_cnn)\n","plt.plot(fpr_valid_dense, tpr_valid_dense, 'r-', label = 'Dense AUC:%.3f'%auc_valid_dense)\n","plt.plot(fpr_valid_lstm, tpr_valid_lstm, 'b-', label = 'LSTM AUC:%.3f'%auc_valid_lstm)\n","\n","plt.plot([0,1],[0,1], 'k--')\n","plt.xlabel('FPR')\n","plt.ylabel('TPR')\n","plt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\n","plt.title('Validation Set')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJHup47CMvA3","executionInfo":{"status":"aborted","timestamp":1683545067379,"user_tz":-210,"elapsed":107,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyiGIKoHMvA4","executionInfo":{"status":"aborted","timestamp":1683545067380,"user_tz":-210,"elapsed":107,"user":{"displayName":"Ayda Zaman","userId":"05005701064032709211"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"tutorials","language":"python","name":"tutorials"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}